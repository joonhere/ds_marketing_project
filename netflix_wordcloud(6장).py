import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from wordcloud import WordCloud
from PIL import Image
import random
from typing import Optional, Dict, Any, Set, List, Tuple
import re # ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©

# --- ìƒìˆ˜ ì •ì˜ (ìœ ì§€ë³´ìˆ˜ ìš©ì´ì„± í™•ë³´) ---
CSV_FILE = 'netflix_preprocessed.csv'
MASK_FILE = 'netflix_logo.jpg'
PLOT_TITLE_WC = 'Keywords in KOREAN Netflix Content Descriptions'
PLOT_TITLE_GENRE = 'Top 10 Genres in KOREAN Netflix Content'
TEXT_COLUMN = 'description'
COUNTRY_COLUMN = 'country'
GENRE_COLUMN = 'listed_in'
RANDOM_SEED = 42

# ğŸ’¡ U+00A0 ì˜¤ë¥˜ ë°©ì§€: í•œ ì¤„ë¡œ ì •ì˜í•¨
DEFAULT_STOPWORDS = {'series', 'film', 'movie', 'show', 'story', 'life', 'new', 'world', 'us', 'based', 'one', 'two', 'young', 'old', 'about', 'from', 'with', 'who', 'when', 'what', 'where', 'their', 'they', 'them', 'this', 'that', 'these', 'those', 'also', 'after', 'before', 'just', 'much', 'many', 'more', 'most', 'very', 'get', 'got', 'make', 'made', 'take', 'takes', 'find', 'found', 'come', 'comes', 'go', 'goes', 'see', 'saw', 'said', 'say', 'into', 'through', 'while', 'upon', 'among', 'across', 'always', 'ever', 'never', 'might', 'must', 'should', 'could', 'would', 'can', 'will', 'may', 'way', 'time', 'years', 'first', 'their', 'all', 'its', 'her', 'his', 'which', 'had', 'etc', 'korean', 'korea', 'drama', 'kdrama', 'a', 'an', 'to', 'of', 'for', 'in', 'on', 'at', 'and', 'the', 'is', 'but', 'as', 'by', 'he', 'she', 'out', 'up'}

# --- 1. ë°ì´í„° ë¡œë“œ ë° í•„í„°ë§ ---

def load_and_filter_data(file_path: str, country_col: str, genre_col: str) -> Optional[pd.DataFrame]:
    """ì§€ì •ëœ CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  'Korea' ê´€ë ¨ ì½˜í…ì¸ ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."""
    try:
        df = pd.read_csv(file_path)
        korea_df = df[
            df[country_col].fillna('').str.contains('Korea', case=False, na=False) |
            df[genre_col].fillna('').str.contains('Korean', case=False, na=False)
        ].copy()
        
        if korea_df.empty:
            print("ğŸš¨ ê²½ê³ : 'Korea' ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        return korea_df
    except FileNotFoundError:
        print(f"ğŸš¨ ì˜¤ë¥˜: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ë‹¨.")
        return None
    except KeyError as e:
        print(f"ğŸš¨ ì˜¤ë¥˜: í•„ìˆ˜ ì»¬ëŸ¼ '{e}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ í™•ì¸ í•„ìš”.")
        return None

# --- 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ---

def engineer_korea_features(df: pd.DataFrame, text_col: str, genre_col: str) -> Tuple[pd.DataFrame, pd.Series]:
    """KOREA ì½˜í…ì¸  ë°ì´í„°í”„ë ˆì„ì— ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ì—”ì§€ë‹ˆì–´ë§í•˜ê³ , ì¥ë¥´ ë¹ˆë„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    all_k_genres = df[genre_col].str.split(', ').explode().dropna()
    k_genre_counts = all_k_genres.value_counts().head(10)
    df['K_Drama_Flag'] = df[text_col].fillna('').apply(
        lambda x: 1 if 'drama' in x.lower() or 'kdrama' in x.lower() else 0
    )
    return df, k_genre_counts

# --- 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ---

def preprocess_text_for_wordcloud(df: pd.DataFrame, text_col: str, stopwords: Set[str]) -> str:
    """ì›Œë“œ í´ë¼ìš°ë“œìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    clean_descriptions = df[text_col].fillna('')
    combined_text = clean_descriptions.str.cat(sep=' ')
    combined_text = re.sub(r'[^ê°€-í£a-zA-Z\s]', '', combined_text) 
    combined_text = combined_text.lower()
    
    words = combined_text.split()
    filtered_words = [word for word in words if word not in stopwords and len(word) > 1] 
    
    return ' '.join(filtered_words)

# --- 4. ì›Œë“œ í´ë¼ìš°ë“œ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° ---

def load_mask(mask_path: str) -> Optional[np.ndarray]:
    """ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  NumPy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return np.array(Image.open(mask_path))
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : {mask_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë§ˆìŠ¤í¬ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        return None

def netflix_color_func(word: str, font_size: int, position: tuple, orientation: int, 
                       random_state: Optional[int] = None, **kwargs: Dict[str, Any]) -> str:
    """WordCloud ê°ì²´ë¥¼ ìœ„í•œ ë„·í”Œë¦­ìŠ¤ í…Œë§ˆ(ë ˆë“œ, ë¸”ë™) ë¬´ì‘ìœ„ ìƒ‰ìƒ ì„ íƒ í•¨ìˆ˜."""
    colors = ['#221F1F', '#B20710'] 
    return random.choice(colors)

def generate_wordcloud_object(text: str, mask: Optional[np.ndarray], stopwords: Set[str]) -> WordCloud:
    """ê²°í•©ëœ í…ìŠ¤íŠ¸ì™€ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ WordCloud ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return WordCloud(
        background_color='white',
        width=1400,
        height=1400,
        max_words=170,
        mask=mask,
        color_func=netflix_color_func,
        collocations=False, 
        stopwords=stopwords, 
        random_state=RANDOM_SEED
    ).generate(text)

# --- 5. ì‹œê°í™” í•¨ìˆ˜ ---

def plot_genre_distribution(genre_counts: pd.Series, title: str) -> None:
    """Seabornì„ ì‚¬ìš©í•˜ì—¬ KOREA ì½˜í…ì¸ ì˜ ì¥ë¥´ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ê³  í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."""
    plt.figure(figsize=(12, 6))
    
    sns.barplot(
        x=genre_counts.index, 
        y=genre_counts.values,
        hue=genre_counts.index, 
        palette='viridis',
        legend=False
    )
    plt.title(title, fontsize=16, fontweight='bold')
    plt.xlabel('Genre', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

def save_wordcloud_image_final(wordcloud: WordCloud, title: str, filename: str = "korean_netflix_wordcloud.png") -> None:
    """
    ì›Œë“œ í´ë¼ìš°ë“œ ê²°ê³¼ë¬¼ì„ íŒŒì¼ë¡œ ì§ì ‘ ì €ì¥í•˜ë©°, bbox_inches='tight'ë¡œ ì œëª© ì˜ë¦¼ì„ ë°©ì§€í•˜ê³  í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    plt.figure(figsize=(15, 6)) 
    
    # suptitle ì„¤ì • (y ê°’ì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì •í•  í•„ìš” ì—†ì´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    plt.suptitle(title, fontweight='bold', fontfamily='serif', fontsize=18) 
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')

    # â­ Critical Path Solution: bbox_inches='tight'ë¡œ ëª¨ë“  ìš”ì†Œê°€ í¬í•¨ë˜ë„ë¡ ì €ì¥í•©ë‹ˆë‹¤.
    try:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"âœ… ì›Œë“œ í´ë¼ìš°ë“œ ì´ë¯¸ì§€ê°€ '{filename}' íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("íŒŒì¼ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í´ë”ì— ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    # ğŸ’¡ í™”ë©´ ì¶œë ¥ ì¶”ê°€: ì´ ë•Œ í™”ë©´ìƒì—ì„œëŠ” ì œëª©ì´ ì˜ë ¤ ë³´ì¼ ìˆ˜ ìˆìœ¼ë‚˜, íŒŒì¼ì€ ì™„ë²½í•©ë‹ˆë‹¤.
    plt.show() 
    plt.close()

# --- ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---
if __name__ == "__main__":
    print("--- ë„·í”Œë¦­ìŠ¤ KOREA ì½˜í…ì¸  ë¶„ì„ ì‹œì‘ ---")

    # 1. ë°ì´í„° ë¡œë“œ ë° í•„í„°ë§
    korea_df_filtered = load_and_filter_data(CSV_FILE, COUNTRY_COLUMN, GENRE_COLUMN)
    if korea_df_filtered is None:
        exit()

    # 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    korea_df_processed, k_top_genres = engineer_korea_features(
        korea_df_filtered, TEXT_COLUMN, GENRE_COLUMN
    )
    print(f"\nKOREA ì½˜í…ì¸  ì´ {len(korea_df_processed)}ê°œ ë°œê²¬.")
    
    # 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    wordcloud_text = preprocess_text_for_wordcloud(
        korea_df_processed, TEXT_COLUMN, DEFAULT_STOPWORDS
    )
    if not wordcloud_text: 
        print("ğŸš¨ ì˜¤ë¥˜: ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")
        exit()

    # 4. ë§ˆìŠ¤í¬ ë¡œë“œ
    mask_array = load_mask(MASK_FILE)

    # 5. ì›Œë“œ í´ë¼ìš°ë“œ ê°ì²´ ìƒì„±
    wordcloud_obj = generate_wordcloud_object(
        wordcloud_text, mask_array, DEFAULT_STOPWORDS
    )

    # 6. ê²°ê³¼ ì‹œê°í™”
    print("\n--- ë¶„ì„ ê²°ê³¼ ì‹œê°í™” ---")
    
    # 6.1. ì¥ë¥´ ë¶„í¬ ê·¸ë˜í”„ (í™”ë©´ í‘œì‹œ)
    plot_genre_distribution(k_top_genres, PLOT_TITLE_GENRE)
    
    # 6.2. ì›Œë“œ í´ë¼ìš°ë“œ (íŒŒì¼ ì €ì¥ ë° í™”ë©´ ì¶œë ¥)
    save_wordcloud_image_final(wordcloud_obj, PLOT_TITLE_WC)

    print("--- ë„·í”Œë¦­ìŠ¤ KOREA ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ ---")